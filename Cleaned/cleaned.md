# ğŸ§¹ Data Cleaning & Preprocessing Log

This document records all preprocessing, cleaning, and transformation steps applied to the dataset before analysis and dashboard creation.

---

## ğŸ“Š Dataset Overview
- Original Rows: **148,670**
- Working Rows: **24,999**
- Goal: Prepare dataset for reliable analysis and visualization.

---

# ğŸ—‘ Dropped Columns

The following columns were removed due to lack of analytical value:

| Column | Reason |
|------|--------|
year | Same value across all rows |
loan_type | Encoded categories not interpretable |
loan_purpose | Encoded values without meaning |
total_units | Not relevant for risk analysis |
security_type | Same value for entire column |

---

# âœ Column Renaming

| Old Name | New Name | Reason |
|---------|----------|-------|
status | defaulted | Clear target variable name |

---

# ğŸ”¤ Text Standardization

All categorical columns were cleaned using:

=UPPER(TRIM(A2))

Purpose:
- remove extra spaces
- standardize case
- avoid duplicate categories

Columns standardized:
- loan_limit
- gender
- approv_in_adv
- open_credit
- business_or_commercial
- neg_ammortization
- interest_only
- lump_sum_payment
- construction_type
- occupancy_type
- secured_by
- credit_type
- co-applicant_credit_type
- region

---

# ğŸ“Š Missing Value Treatment Strategy

| Data Type | Method Used | Reason |
|----------|-------------|-------|
Categorical | Mode | Most frequent category best represents missing values |
Numeric | Median | Robust against outliers |

---

## ğŸŸ¡ Mode Imputation Columns (Categorical)

The following columns had missing values replaced using **mode**:

| Column | Missing Count | Action |
|------|----------------|-------|
loan_limit | 603 | Filled with mode |
approv_in_adv | 166 | Filled with mode |
neg_ammortization | 25 | Filled with mode |
age | 31 | Filled with mode |
submission_of_application | 31 | Filled with mode |

Reason:  
Mode imputation is appropriate for categorical variables because it preserves category distribution and avoids introducing artificial values.

---

## ğŸ”µ Median Imputation Columns (Numeric)

Median replacement was applied to:

- rate_of_interest (6070 missing)
- interest_rate_spread (6101 missing)
- upfront_charges (6594 missing)
- term (8 missing)
- property_value (2419 missing)
- income (1558 missing)
- ltv (2419 missing)
- dtir1 (3955 missing)

Reason:  
Median is resistant to extreme values and maintains realistic distributions.

---

# ğŸ“ˆ Outlier Handling

## Income Column
Issues detected:
- missing values
- invalid values (0)
- extreme outliers

Method used:
- median replacement
- IQR outlier detection

Formula used:
=ARRAYFORMULA(IF(U2:U="","",
IF((U2:U=0)+
(U2:U < QUARTILE(U:U,1)-1.5*(QUARTILE(U:U,3)-QUARTILE(U:U,1)))+
(U2:U > QUARTILE(U:U,3)+1.5*(QUARTILE(U:U,3)-QUARTILE(U:U,1))),
MEDIAN(FILTER(U:U,U:U>0)),
U2:U)))

---

# ğŸ”¢ Numeric Formatting
The following columns were standardized to **2 decimal places**:

- rate_of_interest
- interest_rate_spread
- upfront_charges
- ltv

---

# âš™ Feature Engineering

## Credit Score Band Column
A new column **credit_score_band** was created to group credit scores into ranges:

450â€“499
500â€“549
550â€“599
600â€“649
650â€“699
700â€“749
750â€“799
800â€“850
851â€“900

Purpose:
- easier analysis
- clearer charts
- grouped comparisons

---

# âœ… Final Dataset State

After preprocessing:

âœ” Missing values handled  
âœ” Outliers corrected  
âœ” Invalid ranges fixed  
âœ” Categories standardized  
âœ” Irrelevant columns removed  
âœ” Dataset consistent and analysis-ready  

---

# ğŸ“Œ Conclusion
All preprocessing steps were designed to:

- preserve data integrity
- reduce noise
- improve statistical reliability
- ensure accurate analytical insights
